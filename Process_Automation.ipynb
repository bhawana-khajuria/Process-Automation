{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6J1JisaSK0s6Wtf6tZrZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhawana-khajuria/Process-Automation/blob/main/Process_Automation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Process Automation**\n",
        "---"
      ],
      "metadata": {
        "id": "bH9g6uzM-rnb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**1.File with 1000 lines of random strings**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "cdehHxDl--y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "with open(\"random_1000_lines.txt\", \"w\") as f:\n",
        "    for _ in range(1000):\n",
        "        line = ''.join(random.choices(string.ascii_letters + string.digits, k=50))\n",
        "        f.write(line + \"\\n\")"
      ],
      "metadata": {
        "id": "NCJRPWQb-1qr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**2.File that contains multiple lines of random strings and file size must be 5 MB.**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "4EVLGceoAPz6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_file_5mb(filename):\n",
        "    with open(filename, \"w\") as f:\n",
        "        while f.tell() < 5 * 1024 * 1024:  # 5 MB\n",
        "            line = ''.join(random.choices(string.ascii_letters + string.digits, k=100))\n",
        "            f.write(line + \"\\n\")\n",
        "\n",
        "generate_file_5mb(\"file_5mb.txt\")"
      ],
      "metadata": {
        "id": "p4ERCLWiAdOL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**3.10 files that contains multiple lines of random strings and file size of each file must be 5 MB.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "NkVN6DwLB4dy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    generate_file_5mb(f\"file_5mb_{i+1}.txt\")"
      ],
      "metadata": {
        "id": "Y0RDzMWHB4tU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**4. 5 files of size 1GB, 2GB, 3GB, 4GB and 5GB; file contains multiple lines of random strings.**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "cZhqZsWgCicZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_large_file(filename, size_gb):\n",
        "    with open(filename, \"w\") as f:\n",
        "        while f.tell() < size_gb * 1024 * 1024 * 1024:\n",
        "            line = ''.join(random.choices(string.ascii_letters + string.digits, k=100))\n",
        "            f.write(line + \"\\n\")\n",
        "\n",
        "for i in range(1, 6):\n",
        "    generate_large_file(f\"file_{i}GB.txt\", i)"
      ],
      "metadata": {
        "id": "GQSNFWH3ElLA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**5.Convert all the files of Q4 into upper case one by one.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GhKwBq3aFB8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_uppercase(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        content = f.read().upper()\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "for i in range(1, 6):\n",
        "    convert_to_uppercase(f\"file_{i}GB.txt\")"
      ],
      "metadata": {
        "id": "7JdkhDQhLJC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**6.Convert all the files of Q4 into upper case parallel using multi-threading.**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "uTUBiZMOFY7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import random\n",
        "import string\n",
        "\n",
        "def convert_to_uppercase(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        content = f.read().upper()\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "threads = []\n",
        "\n",
        "for i in range(1, 6):\n",
        "    t = threading.Thread(target=convert_to_uppercase, args=(f\"file_{i}GB.txt\",))\n",
        "    t.start()\n",
        "    threads.append(t)\n",
        "\n",
        "for t in threads:\n",
        "    t.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAWdgBO7FnqZ",
        "outputId": "ab21eef2-9f6b-4bee-b500-ca56b7d8a95e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-4 (convert_to_uppercase):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "Exception in thread Thread-5 (convert_to_uppercase):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/tmp/ipython-input-1-395830150.py\", line 6, in convert_to_uppercase\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'file_1GB.txt'\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/tmp/ipython-input-1-395830150.py\", line 6, in convert_to_uppercase\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'file_2GB.txt'\n",
            "Exception in thread Thread-6 (convert_to_uppercase):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/tmp/ipython-input-1-395830150.py\", line 6, in convert_to_uppercase\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'file_3GB.txt'\n",
            "Exception in thread Thread-7 (convert_to_uppercase):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/tmp/ipython-input-1-395830150.py\", line 6, in convert_to_uppercase\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'file_4GB.txt'\n",
            "Exception in thread Thread-8 (convert_to_uppercase):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/tmp/ipython-input-1-395830150.py\", line 6, in convert_to_uppercase\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'file_5GB.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**7. WAP to automatically download 10 images of cat from “Google Images”**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ySIFX0oHFokO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from icrawler.builtin import GoogleImageCrawler\n",
        "\n",
        "crawler = GoogleImageCrawler(storage={'root_dir': 'cat_images'})\n",
        "crawler.crawl(keyword='cat', max_num=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dpn2a1h6OXhP",
        "outputId": "d7ac135d-cbd6-44ac-860e-ea5228cd68c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Cat_August_2010-4.jpg\n",
            "ERROR:downloader:Response status code 404, file https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg\n",
            "ERROR:downloader:Response status code 403, file http://www.alleycat.org/wp-content/uploads/2019/03/FELV-cat.jpg\n",
            "ERROR:downloader:Response status code 400, file https://media.istockphoto.com/id/1443562748/photo/cute-ginger-cat.jpg\n",
            "ERROR:downloader:Response status code 401, file https://i.guim.co.uk/img/media/327aa3f0c3b8e40ab03b4ae80319064e401c6fbc/377_133_3542_2834/master/3542.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**8.WAP to automatically download 10 videos of “Machine Learning” from “Youtube.com”.**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "qg7rWB1tPqPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube youtube-search-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUgjy0Yy4OpF",
        "outputId": "ca4396f9-6c48-4f12-83f9-f60406f75450"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
            "Collecting youtube-search-python\n",
            "  Downloading youtube_search_python-1.6.6-py3-none-any.whl.metadata (99 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/99.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.14.2 in /usr/local/lib/python3.11/dist-packages (from youtube-search-python) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.14.2->youtube-search-python) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.14.2->youtube-search-python) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.14.2->youtube-search-python) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.14.2->youtube-search-python) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.14.2->youtube-search-python) (0.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.14.2->youtube-search-python) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.14.2->youtube-search-python) (4.14.0)\n",
            "Downloading youtube_search_python-1.6.6-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube-search-python\n",
            "Successfully installed youtube-search-python-1.6.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "# Removed import of youtubesearchpython as it's causing a TypeError\n",
        "import os\n",
        "\n",
        "# Folder to save videos\n",
        "video_folder = \"ml_videos\"\n",
        "os.makedirs(video_folder, exist_ok=True)\n",
        "\n",
        "# Use the hardcoded list of video links from cell ijayntIykbUT\n",
        "video_links = [\n",
        "    (\"Machine Learning Crash Course\", \"https://www.youtube.com/watch?v=GwIo3gDZCVQ\"),\n",
        "    (\"Deep Learning Basics\", \"https://www.youtube.com/watch?v=aircAruvnKk\"),\n",
        "    (\"PyTorch Full Course - Deep Learning\", \"https://www.youtube.com/watch?v=GIsg-ZUy0MY\"),\n",
        "    (\"Visualizing Neural Networks with Grad-CAM\", \"https://www.youtube.com/watch?v=KxvKCSwlUv8\"),\n",
        "    (\"Training CNNs on Custom Datasets\", \"https://www.youtube.com/watch?v=RznKVRTFkBY\"),\n",
        "    (\"How Optimizers Work in Deep Learning\", \"https://www.youtube.com/watch?v=JWU7PbpKjJk\"),\n",
        "    (\"Understanding Overfitting & Regularization\", \"https://www.youtube.com/watch?v=J5rZUX5D6fQ\"),\n",
        "    (\"TensorBoard for PyTorch\", \"https://www.youtube.com/watch?v=zFVxXGMDX9U\"),\n",
        "    (\"Deploying ML Models with Flask\", \"https://www.youtube.com/watch?v=UbC9a4dGn94\"),\n",
        "    (\"What is Backpropagation?\", \"https://www.youtube.com/watch?v=Ilg3gGewQ5U\")\n",
        "]\n",
        "\n",
        "\n",
        "# Download each video\n",
        "for title, url in video_links: # Iterate over the list of tuples\n",
        "    try:\n",
        "        yt = YouTube(url)\n",
        "        stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
        "        if stream:\n",
        "            print(f\"⬇️ Downloading: {yt.title}\")\n",
        "            stream.download(output_path=video_folder)\n",
        "            print(f\"✅ Saved to {video_folder}\\n\")\n",
        "        else:\n",
        "            print(f\"⚠️ No downloadable stream for {url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error downloading {url}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AYwFKgf4Z7u",
        "outputId": "ca4e7c42-2aff-4f86-b381-dbfa9e99f1d1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error downloading https://www.youtube.com/watch?v=GwIo3gDZCVQ: HTTP Error 400: Bad Request\n",
            "❌ Error downloading https://www.youtube.com/watch?v=aircAruvnKk: HTTP Error 400: Bad Request\n",
            "❌ Error downloading https://www.youtube.com/watch?v=GIsg-ZUy0MY: HTTP Error 400: Bad Request\n",
            "❌ Error downloading https://www.youtube.com/watch?v=KxvKCSwlUv8: HTTP Error 400: Bad Request\n",
            "❌ Error downloading https://www.youtube.com/watch?v=RznKVRTFkBY: HTTP Error 400: Bad Request\n",
            "❌ Error downloading https://www.youtube.com/watch?v=JWU7PbpKjJk: JWU7PbpKjJk is unavailable\n",
            "❌ Error downloading https://www.youtube.com/watch?v=J5rZUX5D6fQ: J5rZUX5D6fQ is unavailable\n",
            "❌ Error downloading https://www.youtube.com/watch?v=zFVxXGMDX9U: zFVxXGMDX9U is unavailable\n",
            "❌ Error downloading https://www.youtube.com/watch?v=UbC9a4dGn94: UbC9a4dGn94 is unavailable\n",
            "❌ Error downloading https://www.youtube.com/watch?v=Ilg3gGewQ5U: HTTP Error 400: Bad Request\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**9.Convert all the videos of Q8 and convert it to audio**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7c23hnufk4dd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "import os\n",
        "\n",
        "video_folder = \"ml_videos\"\n",
        "audio_folder = \"ml_audios\"\n",
        "os.makedirs(audio_folder, exist_ok=True)\n",
        "\n",
        "for filename in os.listdir(video_folder):\n",
        "    if filename.endswith(\".mp4\"):\n",
        "        video_path = os.path.join(video_folder, filename)\n",
        "        try:\n",
        "            clip = VideoFileClip(video_path)\n",
        "            if clip.audio is None:\n",
        "                print(f\"⚠️ No audio in {filename}, skipping...\")\n",
        "                continue\n",
        "            audio_path = os.path.join(audio_folder, filename.replace(\".mp4\", \".mp3\"))\n",
        "            clip.audio.write_audiofile(audio_path)\n",
        "            print(f\"✅ Converted: {filename} → {audio_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error processing {filename}: {e}\")"
      ],
      "metadata": {
        "id": "QkN1sjEXlN-5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube moviepy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP0pIP5033hv",
        "outputId": "48ba4fe9-5b7c-44ff-b512-8172c389ef1b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.11/dist-packages (15.0.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.32.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.0.2)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**10.Create an automated pipeline using multi-threading for:\n",
        "“Automatic Download of 100 Videos from YouTube” → “Convert it to Audio”**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "zlPELdWglWKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import queue\n",
        "\n",
        "video_links = [url.watch_url for url in Search(\"Machine Learning\").results[:100]]\n",
        "q = queue.Queue()\n",
        "\n",
        "for link in video_links:\n",
        "    q.put(link)\n",
        "\n",
        "def process_video():\n",
        "    while not q.empty():\n",
        "        try:\n",
        "            url = q.get()\n",
        "            yt = YouTube(url)\n",
        "            video = yt.streams.filter(progressive=True, file_extension='mp4').first()\n",
        "            filename = yt.title.replace(\" \", \"_\").replace(\"/\", \"\") + \".mp4\"\n",
        "            video.download(output_path=\"yt100_videos\", filename=filename)\n",
        "\n",
        "            # Convert to audio\n",
        "            clip = VideoFileClip(f\"yt100_videos/{filename}\")\n",
        "            clip.audio.write_audiofile(f\"yt100_audios/{filename.replace('.mp4', '.mp3')}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "\n",
        "threads = [threading.Thread(target=process_video) for _ in range(10)]\n",
        "for t in threads: t.start()\n",
        "for t in threads: t.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kxu3srl8lWg3",
        "outputId": "97c777e1-2828-4454-ee2f-e197c5d1bacc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pytube.contrib.search:Unexpected renderer encountered.\n",
            "WARNING:pytube.contrib.search:Renderer name: dict_keys(['lockupViewModel'])\n",
            "WARNING:pytube.contrib.search:Search term: Machine Learning\n",
            "WARNING:pytube.contrib.search:Please open an issue at https://github.com/pytube/pytube/issues and provide this log output.\n",
            "WARNING:pytube.contrib.search:Unexpected renderer encountered.\n",
            "WARNING:pytube.contrib.search:Renderer name: dict_keys(['lockupViewModel'])\n",
            "WARNING:pytube.contrib.search:Search term: Machine Learning\n",
            "WARNING:pytube.contrib.search:Please open an issue at https://github.com/pytube/pytube/issues and provide this log output.\n",
            "WARNING:pytube.contrib.search:Unexpected renderer encountered.\n",
            "WARNING:pytube.contrib.search:Renderer name: dict_keys(['lockupViewModel'])\n",
            "WARNING:pytube.contrib.search:Search term: Machine Learning\n",
            "WARNING:pytube.contrib.search:Please open an issue at https://github.com/pytube/pytube/issues and provide this log output.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad RequestError: HTTP Error 400: Bad Request\n",
            "\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n",
            "Error: HTTP Error 400: Bad Request\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**11.Create an automated pipeline using multi-threading for: “Automatic Download of 500 images of Dog from\n",
        "GoogleImages” → “Rescale it to 50%”.**\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "08lTiYh3lWzL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from icrawler.builtin import GoogleImageCrawler\n",
        "from PIL import Image\n",
        "import glob\n",
        "import threading # Import threading here\n",
        "\n",
        "# Step 1: Download\n",
        "crawler = GoogleImageCrawler(storage={'root_dir': 'dog_images'})\n",
        "crawler.crawl(keyword='dog', max_num=500)\n",
        "\n",
        "# Step 2: Rescale\n",
        "def resize_image(file_path):\n",
        "    try:\n",
        "        img = Image.open(file_path)\n",
        "        w, h = img.size\n",
        "        img_resized = img.resize((w//2, h//2))\n",
        "        img_resized.save(file_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Failed on {file_path}: {e}\")\n",
        "\n",
        "image_paths = glob.glob(\"dog_images/*.*\")\n",
        "threads = []\n",
        "\n",
        "for path in image_paths:\n",
        "    t = threading.Thread(target=resize_image, args=(path,))\n",
        "    t.start()\n",
        "    threads.append(t)\n",
        "\n",
        "for t in threads:\n",
        "    t.join()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oSUvj9-lXMM",
        "outputId": "74c811d2-b686-417e-cc1e-4fd935afe466"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread parser-001:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/icrawler/parser.py\", line 93, in worker_exec\n",
            "    for task in self.parse(response, **kwargs):\n",
            "TypeError: 'NoneType' object is not iterable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f47f1c6",
        "outputId": "e41106dd-5f36-4c68-dd8d-7c58d2769c29"
      },
      "source": [
        "%pip install icrawler"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icrawler\n",
            "  Downloading icrawler-0.6.10-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from icrawler) (4.13.4)\n",
            "Collecting bs4 (from icrawler)\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from icrawler) (5.4.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from icrawler) (11.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from icrawler) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from icrawler) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from icrawler) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->icrawler) (4.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->icrawler) (2025.6.15)\n",
            "Downloading icrawler-0.6.10-py3-none-any.whl (36 kB)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4, icrawler\n",
            "Successfully installed bs4-0.0.2 icrawler-0.6.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6749dcb7",
        "outputId": "2b042494-2e29-4eaa-855d-7509c5948453"
      },
      "source": [
        "%pip install pytube"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7ba1704",
        "outputId": "6762754b-4331-4993-dde8-14601c7a003b"
      },
      "source": [
        "%pip install --upgrade pytube"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    }
  ]
}